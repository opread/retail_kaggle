{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory is : C:\\Users\\Dragos\\projects\\retail_kaggle\n",
      "the /data folder contains:\n",
      "['Features data set.csv', 'sales data-set.csv', 'stores data-set.csv']\n"
     ]
    }
   ],
   "source": [
    "## Data Source: https://www.kaggle.com/manjeetsingh/retaildataset\n",
    "# read the ['Features data set.csv', 'sales data-set.csv', 'stores data-set.csv'] from the /data folder\n",
    "import os\n",
    "print(\"current directory is : \" + os.getcwd()) \n",
    "print('the /data folder contains:') \n",
    "print(os.listdir(\"./data\"))\n",
    "\n",
    "stores = pd.read_csv('./data/stores data-set.csv')\n",
    "features = pd.read_csv('./data/Features data set.csv')\n",
    "sales = pd.read_csv('./data/sales data-set.csv')\n",
    "\n",
    "## I don't intend to use so instead of replacing na-s with 0 I better drop them all\n",
    "markdown_cols = features.filter(like='MarkDown').columns\n",
    "for column in markdown_cols:\n",
    "     features = features.drop(column,axis=1)\n",
    "\n",
    "# On features Fill na gaps forward on CPI and Unemployment, Data seems sorted by date already\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html\n",
    "features['CPI'] = features['CPI'].fillna(method='pad')\n",
    "features['Unemployment'] = features['Unemployment'].fillna(method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge left all tables, use only keys from left frame, similar to a SQL left outer join; preserve key order.\n",
    "    \n",
    "retail = pd.merge(sales, features, how = 'left', on = ['Store', 'Date', 'IsHoliday'])\n",
    "retail = pd.merge(retail, stores, how = 'left', on = ['Store'])\n",
    "\n",
    "# format date in datetime, we need it to extract Year and Year week later to split the data in train, test\n",
    "retail['Date'] = pd.to_datetime(retail['Date'])\n",
    "retail['Year'] = pd.DatetimeIndex(retail['Date']).year\n",
    "retail['Month'] = pd.DatetimeIndex(retail['Date']).month\n",
    "\n",
    "retail['Year-Week'] = retail['Date'].dt.strftime('%Y-%U')\n",
    "\n",
    "# I noticed there are Sales figures that are negative, cleanup:\n",
    "retail = retail[retail['Weekly_Sales']>=0]\n",
    "\n",
    "# turn IsHoliday into an Integer, useful later for numeric computations\n",
    "retail['IsHoliday'] = retail['IsHoliday'].astype(int)\n",
    "\n",
    "# Sort by Date as the data is not ordered by Date\n",
    "retail = retail.sort_values(by=['Date'])\n",
    "\n",
    "# checkout the dataset we're going to use further\n",
    "retail.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag data, retail data is already ordered by Date\n",
    "for i in range(1,9):\n",
    "    c_name = 'Sales_Lag'+ str(i)\n",
    "    retail[c_name] = retail.groupby(['Store','Dept'])['Weekly_Sales'].shift(-i)\n",
    "    \n",
    "retail.query('Store==1 & Dept==1').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "results_df = []\n",
    "columns = ['Pred_Dt','Store','Dept','Sales_Lag1','Sales_Lag2','Sales_Lag3','Sales_Lag4','Sales_Lag5','Sales_Lag6','Sales_Lag7','Sales_Lag8']\n",
    "results_df = pd.DataFrame(columns=columns) \n",
    "predict_date = '2012-30'\n",
    "    \n",
    "store_list = retail['Store'].unique()\n",
    "for c_store in store_list:\n",
    "    dept_list=retail[retail['Store']==c_store]['Dept'].unique()\n",
    "    for c_dept in dept_list:\n",
    "        tmp_pred = []\n",
    "        for i in range(1,9):\n",
    "            c_name = 'Sales_Lag'+ str(i)\n",
    "            my_cols = ['Date','Year-Week','Temperature','Fuel_Price','CPI','Unemployment','Size', 'Dept', 'IsHoliday']\n",
    "            X_cols = ['Temperature','Fuel_Price','CPI','Unemployment','Size', 'Dept', 'IsHoliday']\n",
    "            my_cols.append(c_name)\n",
    "            retail_tmp = retail.query('Store=={store} & Dept=={dept}'.format(store=c_store, dept=c_dept))[my_cols]      \n",
    "            retail_tmp = retail_tmp.dropna()\n",
    "            # retail_tmp.set_index(retail_tmp['Date'], inplace=True) \n",
    "            X = retail_tmp[X_cols]\n",
    "            y = retail_tmp[c_name]\n",
    "\n",
    "            # print(str(c_store)+ '/' + str(c_dept) + \" Shape: \" + str(retail_tmp.shape))\n",
    "            \n",
    "    \n",
    "            if  X.count()[0]>20:\n",
    "                model =  LinearRegression()\n",
    "                model.fit(X,y)\n",
    "                y_pred = model.predict(X)\n",
    "\n",
    "                # print(mean_squared_error(y, y_pred))\n",
    "                # print(\"R^2: {0:.4f}\".format(r2_score(y, y_pred)))\n",
    "          \n",
    "                \n",
    "                # generate predictions for one \n",
    "                pred_one = retail_tmp[retail_tmp['Year-Week']==predict_date][X_cols]\n",
    "\n",
    " \n",
    "                if pred_one.count()[0]>0: \n",
    "                    y_test_pred = model.predict(pred_one)\n",
    "                   # print(y_test_pred)\n",
    "               \n",
    "                else:\n",
    "                        y_test_pred =0\n",
    "            else:\n",
    "                y_test_pred =0\n",
    "            \n",
    "            tmp_pred.append(float(y_test_pred))    \n",
    "                \n",
    "        results_df = results_df.append({\"Pred_Dt\":predict_date,\"Store\": c_store,'Dept':c_dept,\n",
    "                                        'Sales_Lag1':tmp_pred[0],\n",
    "                                        'Sales_Lag2':tmp_pred[1],\n",
    "                                        'Sales_Lag3':tmp_pred[2],\n",
    "                                        'Sales_Lag4':tmp_pred[3],\n",
    "                                        'Sales_Lag5':tmp_pred[4],\n",
    "                                        'Sales_Lag6':tmp_pred[5],\n",
    "                                        'Sales_Lag7':tmp_pred[6],\n",
    "                                        'Sales_Lag8':tmp_pred[7]}\n",
    "                                       , ignore_index=True)\n",
    "        # print('On' + str(predict_date) + 'the predicted ' + str(c_name) + ' for Store: '+ str(c_store) + \" dept \" + str(c_dept) + \" is:\" + str(float(y_test_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sales_col = results_df.columns[results_df.columns.str.contains(pat = 'Lag')]\n",
    "results_df.set_index('Store')\n",
    "tmp_res= results_df[Sales_col].groupby(results_df['Store']).sum(axis=1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Prediction for each store for the next 8 weeks, as of year-week: ' + str(predict_date))\n",
    "print(tmp_res.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Prediction for the entire network for the next 8 weeks, as of year-week: ' + str(predict_date))\n",
    "print(tmp_res.astype(int).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
